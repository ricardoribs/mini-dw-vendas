# ðŸ›ï¸ Vendas - Mini Data Warehouse & Analytics

Este projeto Ã© uma simulaÃ§Ã£o **End-to-End** de Engenharia de Dados focada no varejo (Vendas Omnichannel). 

O objetivo foi construir um pipeline de dados robusto que ingere dados transacionais, aplica regras de qualidade, modela para Business Intelligence e entrega um Dashboard executivo automatizado.

![Status](https://img.shields.io/badge/Status-ConcluÃ­do-green?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge)
![DuckDB](https://img.shields.io/badge/DuckDB-OLAP-yellow?style=for-the-badge)
![Prefect](https://img.shields.io/badge/Prefect-Orchestration-white?style=for-the-badge)

---

## ðŸ“Š Resultado Final (Dashboard)

O pipeline alimenta um Painel Gerencial no **Looker Studio**, permitindo anÃ¡lise de receita por canal, performance de produtos e geografia.

![Dashboard Preview](./dashboard_final.png)

> **Destaques do NegÃ³cio:**
> * VisÃ£o unificada de canais (Loja FÃ­sica, App e Site).
> * CÃ¡lculo automatizado de Ticket MÃ©dio e KPIs.
> * Monitoramento de meta por Estado (UF).

---

## ðŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O projeto segue a **Medallion Architecture** (Bronze, Silver, Gold), processada localmente com DuckDB e orquestrada via Prefect.

```mermaid
graph LR
    A[ðŸ“¡ Gerador de Dados (Faker)] -->|IngestÃ£o Raw| B[(ðŸ¥‰ Bronze Layer)]
    B -->|Limpeza & Casting| C[(ðŸ¥ˆ Silver Layer)]
    C -->|ValidaÃ§Ã£o de Qualidade| D{ðŸ•µï¸ Data Quality Gate}
    D -->|Passou| E[(ðŸ¥‡ Gold Layer - Star Schema)]
    D -->|Falhou| X[âŒ Alerta de Erro]
    E -->|ExportaÃ§Ã£o CSV| F[ðŸ“ˆ Looker Studio]

    ðŸ› ï¸ Tecnologias e TÃ©cnicas
    Categoria	Tecnologia	Detalhes da ImplementaÃ§Ã£o
Linguagem	Python 3.12	Scripting e manipulaÃ§Ã£o de arquivos.
Banco de Dados	DuckDB	Banco OLAP local para processamento SQL de alta performance.
OrquestraÃ§Ã£o	Prefect	Gerenciamento de fluxo e dependÃªncia de tarefas (Pipeline).
Modelagem	Star Schema	CriaÃ§Ã£o de tabelas Fato e DimensÃ£o na camada Gold.
Qualidade	Pandas	Framework prÃ³prio de validaÃ§Ã£o (Null checks, Regras de negÃ³cio).
VisualizaÃ§Ã£o	Looker Studio	Dashboard interativo com filtros dinÃ¢micos.

ðŸ“‚ Estrutura do Data Lake
O projeto organiza os dados em camadas lÃ³gicas para garantir governanÃ§a:

â—¾ data/bronze: Dados brutos (vendas.csv, clientes.csv) simulando a extraÃ§Ã£o do sistema de origem.

â—¾ data/silver: Dados tratados. CorreÃ§Ã£o de tipos (Data/Decimal), remoÃ§Ã£o de duplicatas e enriquecimento (Joins).

â—¾ data/gold: Dados prontos para consumo.

â—¾ fato_vendas: Tabela transacional otimizada.

â—¾ dim_cliente: DimensÃ£o de perfil e segmentaÃ§Ã£o.

â—¾ dim_produto: DimensÃ£o de catÃ¡logo e categorias.

ðŸš€ Como Executar o Projeto
1. Clonar o repositÃ³rio
git clone [https://github.com/ricardoribs/mini-dw-vendas.git]
cd mini-dw-boticario

2. Instalar dependÃªncias
pip install pandas duckdb faker prefect

3. Rodar o Pipeline (ETL Completo)
Utilize o script do orquestrador para executar todas as tarefas na ordem correta:
python src/pipeline_prefect.py
O output mostrarÃ¡ os logs de execuÃ§Ã£o de cada etapa (Bronze -> Silver -> Gold).

